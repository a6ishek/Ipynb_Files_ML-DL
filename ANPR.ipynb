{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLzEeWyikIo/nkEYxetAAh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a6ishek/Ipynb_Files_ML-DL/blob/main/ANPR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "0lQmdsYVEQtJ",
        "outputId": "31be3fb0-458d-46ff-9516-128b868faa77"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e55e0505b990>\u001b[0m in \u001b[0;36m<cell line: 311>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'original video'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.filters import threshold_local\n",
        "import tensorflow as tf\n",
        "from skimage import measure\n",
        "import imutils\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "def sort_cont(character_contours):\n",
        "    \"\"\"\n",
        "    To sort contours from left to right\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    boundingBoxes = [cv2.boundingRect(c) for c in character_contours]\n",
        "    (character_contours, boundingBoxes) = zip(*sorted(zip(character_contours, boundingBoxes),\n",
        "                                                      key=lambda b: b[1][i], reverse=False))\n",
        "    return character_contours\n",
        "\n",
        "\n",
        "def segment_chars(plate_img, fixed_width):\n",
        "    \"\"\"\n",
        "    extract Value channel from the HSV format of image and apply adaptive thresholding\n",
        "    to reveal the characters on the license plate\n",
        "    \"\"\"\n",
        "    V = cv2.split(cv2.cvtColor(plate_img, cv2.COLOR_BGR2HSV))[2]\n",
        "\n",
        "    T = threshold_local(V, 29, offset=15, method='gaussian')\n",
        "\n",
        "    thresh = (V > T).astype('uint8') * 255\n",
        "\n",
        "    thresh = cv2.bitwise_not(thresh)\n",
        "\n",
        "    # resize the license plate region to a canoncial size\n",
        "    plate_img = imutils.resize(plate_img, width=fixed_width)\n",
        "    thresh = imutils.resize(thresh, width=fixed_width)\n",
        "    bgr_thresh = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # perform a connected components analysis and initialize the mask to store the locations\n",
        "    # of the character candidates\n",
        "    labels = measure.label(thresh, neighbors=8, background=0)\n",
        "\n",
        "    charCandidates = np.zeros(thresh.shape, dtype='uint8')\n",
        "\n",
        "    # loop over the unique components\n",
        "    characters = []\n",
        "    for label in np.unique(labels):\n",
        "        # if this is the background label, ignore it\n",
        "        if label == 0:\n",
        "            continue\n",
        "        # otherwise, construct the label mask to display only connected components for the\n",
        "        # current label, then find contours in the label mask\n",
        "        labelMask = np.zeros(thresh.shape, dtype='uint8')\n",
        "        labelMask[labels == label] = 255\n",
        "\n",
        "        cnts = cv2.findContours(labelMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
        "\n",
        "        # ensure at least one contour was found in the mask\n",
        "        if len(cnts) > 0:\n",
        "\n",
        "            # grab the largest contour which corresponds to the component in the mask, then\n",
        "            # grab the bounding box for the contour\n",
        "            c = max(cnts, key=cv2.contourArea)\n",
        "            (boxX, boxY, boxW, boxH) = cv2.boundingRect(c)\n",
        "\n",
        "            # compute the aspect ratio, solodity, and height ration for the component\n",
        "            aspectRatio = boxW / float(boxH)\n",
        "            solidity = cv2.contourArea(c) / float(boxW * boxH)\n",
        "            heightRatio = boxH / float(plate_img.shape[0])\n",
        "\n",
        "            # determine if the aspect ratio, solidity, and height of the contour pass\n",
        "            # the rules tests\n",
        "            keepAspectRatio = aspectRatio < 1.0\n",
        "            keepSolidity = solidity > 0.15\n",
        "            keepHeight = heightRatio > 0.5 and heightRatio < 0.95\n",
        "\n",
        "            # check to see if the component passes all the tests\n",
        "            if keepAspectRatio and keepSolidity and keepHeight and boxW > 14:\n",
        "                # compute the convex hull of the contour and draw it on the character\n",
        "                # candidates mask\n",
        "                hull = cv2.convexHull(c)\n",
        "\n",
        "                cv2.drawContours(charCandidates, [hull], -1, 255, -1)\n",
        "\n",
        "    _, contours, hier = cv2.findContours(charCandidates, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if contours:\n",
        "        contours = sort_cont(contours)\n",
        "        addPixel = 4  # value to be added to each dimension of the character\n",
        "        for c in contours:\n",
        "            (x, y, w, h) = cv2.boundingRect(c)\n",
        "            if y > addPixel:\n",
        "                y = y - addPixel\n",
        "            else:\n",
        "                y = 0\n",
        "            if x > addPixel:\n",
        "                x = x - addPixel\n",
        "            else:\n",
        "                x = 0\n",
        "            temp = bgr_thresh[y:y + h + (addPixel * 2), x:x + w + (addPixel * 2)]\n",
        "\n",
        "            characters.append(temp)\n",
        "        return characters\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "class PlateFinder:\n",
        "    def __init__(self):\n",
        "        self.min_area = 4500  # minimum area of the plate\n",
        "        self.max_area = 30000  # maximum area of the plate\n",
        "\n",
        "        self.element_structure = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize=(22, 3))\n",
        "\n",
        "    def preprocess(self, input_img):\n",
        "        imgBlurred = cv2.GaussianBlur(input_img, (7, 7), 0)  # old window was (5,5)\n",
        "        gray = cv2.cvtColor(imgBlurred, cv2.COLOR_BGR2GRAY)  # convert to gray\n",
        "        sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=3)  # sobelX to get the vertical edges\n",
        "        ret2, threshold_img = cv2.threshold(sobelx, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        element = self.element_structure\n",
        "        morph_n_thresholded_img = threshold_img.copy()\n",
        "        cv2.morphologyEx(src=threshold_img, op=cv2.MORPH_CLOSE, kernel=element, dst=morph_n_thresholded_img)\n",
        "        return morph_n_thresholded_img\n",
        "\n",
        "    def extract_contours(self, after_preprocess):\n",
        "        _, contours, _ = cv2.findContours(after_preprocess, mode=cv2.RETR_EXTERNAL,\n",
        "                                                    method=cv2.CHAIN_APPROX_NONE)\n",
        "        return contours\n",
        "\n",
        "    def clean_plate(self, plate):\n",
        "        gray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
        "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "        _, contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "        if contours:\n",
        "            areas = [cv2.contourArea(c) for c in contours]\n",
        "            max_index = np.argmax(areas)  # index of the largest contour in the area array\n",
        "\n",
        "            max_cnt = contours[max_index]\n",
        "            max_cntArea = areas[max_index]\n",
        "            x, y, w, h = cv2.boundingRect(max_cnt)\n",
        "            rect = cv2.minAreaRect(max_cnt)\n",
        "            rotatedPlate = plate\n",
        "            if not self.ratioCheck(max_cntArea, rotatedPlate.shape[1], rotatedPlate.shape[0]):\n",
        "                return plate, False, None\n",
        "            return rotatedPlate, True, [x, y, w, h]\n",
        "        else:\n",
        "            return plate, False, None\n",
        "\n",
        "\n",
        "\n",
        "    def check_plate(self, input_img, contour):\n",
        "        min_rect = cv2.minAreaRect(contour)\n",
        "        if self.validateRatio(min_rect):\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            after_validation_img = input_img[y:y + h, x:x + w]\n",
        "            after_clean_plate_img, plateFound, coordinates = self.clean_plate(after_validation_img)\n",
        "            if plateFound:\n",
        "                characters_on_plate = self.find_characters_on_plate(after_clean_plate_img)\n",
        "                if (characters_on_plate is not None and len(characters_on_plate) == 8):\n",
        "                    x1, y1, w1, h1 = coordinates\n",
        "                    coordinates = x1 + x, y1 + y\n",
        "                    after_check_plate_img = after_clean_plate_img\n",
        "                    return after_check_plate_img, characters_on_plate, coordinates\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "\n",
        "    def find_possible_plates(self, input_img):\n",
        "        \"\"\"\n",
        "        Finding all possible contours that can be plates\n",
        "        \"\"\"\n",
        "        plates = []\n",
        "        self.char_on_plate = []\n",
        "        self.corresponding_area = []\n",
        "\n",
        "        self.after_preprocess = self.preprocess(input_img)\n",
        "        possible_plate_contours = self.extract_contours(self.after_preprocess)\n",
        "\n",
        "        for cnts in possible_plate_contours:\n",
        "            plate, characters_on_plate, coordinates = self.check_plate(input_img, cnts)\n",
        "            if plate is not None:\n",
        "                plates.append(plate)\n",
        "                self.char_on_plate.append(characters_on_plate)\n",
        "                self.corresponding_area.append(coordinates)\n",
        "\n",
        "        if (len(plates) > 0):\n",
        "            return plates\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def find_characters_on_plate(self, plate):\n",
        "\n",
        "        charactersFound = segment_chars(plate, 400)\n",
        "        if charactersFound:\n",
        "            return charactersFound\n",
        "\n",
        "    # PLATE FEATURES\n",
        "    def ratioCheck(self, area, width, height):\n",
        "        min = self.min_area\n",
        "        max = self.max_area\n",
        "\n",
        "        ratioMin = 3\n",
        "        ratioMax = 6\n",
        "\n",
        "        ratio = float(width) / float(height)\n",
        "        if ratio < 1:\n",
        "            ratio = 1 / ratio\n",
        "\n",
        "        if (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def preRatioCheck(self, area, width, height):\n",
        "        min = self.min_area\n",
        "        max = self.max_area\n",
        "\n",
        "        ratioMin = 2.5\n",
        "        ratioMax = 7\n",
        "\n",
        "        ratio = float(width) / float(height)\n",
        "        if ratio < 1:\n",
        "            ratio = 1 / ratio\n",
        "\n",
        "        if (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def validateRatio(self, rect):\n",
        "        (x, y), (width, height), rect_angle = rect\n",
        "\n",
        "        if (width > height):\n",
        "            angle = -rect_angle\n",
        "        else:\n",
        "            angle = 90 + rect_angle\n",
        "\n",
        "        if angle > 15:\n",
        "            return False\n",
        "        if (height == 0 or width == 0):\n",
        "            return False\n",
        "\n",
        "        area = width * height\n",
        "        if not self.preRatioCheck(area, width, height):\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        self.model_file = \"/binary_128_0.50_ver3.pb\"\n",
        "        self.label_file = \"/binary_128_0.50_labels_ver2.txt.txt\"\n",
        "        self.label = self.load_label(self.label_file)\n",
        "        self.graph = self.load_graph(self.model_file)\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "\n",
        "    def load_graph(self, modelFile):\n",
        "        graph = tf.Graph()\n",
        "        graph_def = tf.compat.v1.GraphDef()\n",
        "        with open(modelFile, \"rb\") as f:\n",
        "            graph_def.ParseFromString(f.read())\n",
        "        with graph.as_default():\n",
        "            tf.import_graph_def(graph_def)\n",
        "        return graph\n",
        "\n",
        "    def load_label(self, labelFile):\n",
        "        label = []\n",
        "        proto_as_ascii_lines = tf.io.gfile.GFile(labelFile).readlines()\n",
        "        for l in proto_as_ascii_lines:\n",
        "            label.append(l.rstrip())\n",
        "        return label\n",
        "\n",
        "    def convert_tensor(self, image, imageSizeOuput):\n",
        "        \"\"\"\n",
        "    takes an image and tranform it in tensor\n",
        "    \"\"\"\n",
        "        image = cv2.resize(image, dsize=(imageSizeOuput, imageSizeOuput), interpolation=cv2.INTER_CUBIC)\n",
        "        np_image_data = np.asarray(image)\n",
        "        np_image_data = cv2.normalize(np_image_data.astype('float'), None, -0.5, .5, cv2.NORM_MINMAX)\n",
        "        np_final = np.expand_dims(np_image_data, axis=0)\n",
        "        return np_final\n",
        "\n",
        "    def label_image(self, tensor):\n",
        "\n",
        "        input_name = \"import/input\"\n",
        "        output_name = \"import/final_result\"\n",
        "\n",
        "        input_operation = self.graph.get_operation_by_name(input_name)\n",
        "        output_operation = self.graph.get_operation_by_name(output_name)\n",
        "\n",
        "        results = self.sess.run(output_operation.outputs[0],\n",
        "                                {input_operation.outputs[0]: tensor})\n",
        "        results = np.squeeze(results)\n",
        "        labels = self.label\n",
        "        top = results.argsort()[-1:][::-1]\n",
        "        return labels[top[0]]\n",
        "\n",
        "    def label_image_list(self, listImages, imageSizeOuput):\n",
        "        plate = \"\"\n",
        "        for img in listImages:\n",
        "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "                break\n",
        "            plate = plate + self.label_image(self.convert_tensor(img, imageSizeOuput))\n",
        "        return plate, len(plate)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    findPlate = PlateFinder()\n",
        "\n",
        "    # Initialize the Neural Network\n",
        "    model = NeuralNetwork()\n",
        "\n",
        "    cap = cv2.VideoCapture('/VID_20230401_193801.mp4')\n",
        "    while (cap.isOpened()):\n",
        "        ret, img = cap.read()\n",
        "        if ret == True:\n",
        "            cv2.imshow('original video', img)\n",
        "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "                break\n",
        "            # cv2.waitKey(0)\n",
        "            possible_plates = findPlate.find_possible_plates(img)\n",
        "            if possible_plates is not None:\n",
        "                for i, p in enumerate(possible_plates):\n",
        "                    chars_on_plate = findPlate.char_on_plate[i]\n",
        "                    recognized_plate, _ = model.label_image_list(chars_on_plate, imageSizeOuput=128)\n",
        "                    print(recognized_plate)\n",
        "                    cv2.imshow('plate', p)\n",
        "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "                        break\n",
        "\n",
        "\n",
        "        else:\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    }
  ]
}